{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho prático II - Classificação\n",
    "\n",
    "O objetivo deste trabalho é praticar os conceitos de aprendizado supervisionado que vimos em sala.\n",
    "\n",
    "A sua tarefa será treinar um classificador para um conjunto de dados misterioso (se eu falasses qual é o objetivo do modelo, você encontraria soluções na Internet).\n",
    "\n",
    "Baixe o arquivo [t2.tar.gz](https://drive.google.com/file/d/125plHKUzFGxHjjCiVJcTQG2bPG_zgDNV/view?usp=sharing). Descoprima este arquivo para encontrar outros quatro. Os arquivos `train_X.csv` e `train_y.csv` possuem os dados que você deve usar para treinar o modelo. O arquivo `test_X.csv` possui os objetos para os quais você deve encontrar as classes (testar o modelo). Por fim, o arquivo `test_example_y.csv` é um exemplo de como sua solução final deve ser organizada.\n",
    "\n",
    "Cada linha dos arquivos `train_X.csv` e `test_X.csv` tem 15 campos descrevendo um objeto misterioso. O campo `id` representa o identificador do objeto, sendo que este campo não deve ser considerado em seu modelo. Os atributos a serem usados no modelo são os 14 campos rotulados de de `a` até `n`. Desses atributos:\n",
    "- `b`, `d`, `f`, `g`, `h`, `i`, `j` e `n` são categóricos; e\n",
    "- `a`, `c`, `e`, `k`, `l` e `m` são numéricos.\n",
    "\n",
    "Cada linha do arquivo `train_y.csv` possui dois campos. O primeiro é o identificador de um objeto do arquivo `train_X.csv` e o segundo é a classe do respectivo objeto (0 ou 1).\n",
    "\n",
    "Seu objetivo é encontrar as classes dos objetos do arquivo `test_X.csv` e mostrar como chegou em sua solução! Os dados do arquivo de teste foram obtido a partir de uma amostra aleatório do todo. Ou seja, um modelo bem treinado, e sem _overfitting_, em `train_X.csv` e `train_y.csv` se sairá bem em `test_X.csv`.\n",
    "\n",
    "**Data de entrega:** dia 4 de julho de 2018.\n",
    "\n",
    "**Grupo:** de até 3 pessoas, mas duas pessoas do mesmo grupo no trabalho 1 não podem pertencer ao mesmo grupo nesse trabalho.\n",
    "\n",
    "**Valor:** 20% da nota do semestre.\n",
    "\n",
    "Os três seguintes pontos descrevem o que obrigatoriamente deve ser entregue, com seu respectivo valor.\n",
    "\n",
    "1 - **[10 pontos]** Este notebook com todo seu código e resultados (números, tabelas e gráficos). Você pode usar qualquer um dos métodos que estudamos ou alguma de suas variações próximas. Se estiver na dúvida se pode usar um método, basta perguntas no Piazza. Comentários e justificativas no notebook não serão considerados para sua nota.\n",
    "O notebook deve ser enviado para o email do professor.\n",
    "\n",
    "2 - **[8 pontos]** Um relatório digitado contendo: capa, introdução, metodologia, resultados, conclusão e referências. O relatório deve ter no máximo 10 páginas, com coluna simples, fonte 11, espaçamento 1.5 e margens de 2cm. A seção de metodologia deve conter uma descrição detalhada dos passos seguidos (não incluir código no relatório). A seção de resultados deve conter obrigatoriamente: uma caracterização descritiva dos dados, matriz de confusão das predições, _precision_, _recall_, _F1 score_ e acurácia. Todas as métricas de predição devem ser calculadas a partir dos arquivos de treinamento por meio de validação cruzada.\n",
    "O relatório deve ser enviado para o email do professor.\n",
    "\n",
    "3 - **[2 pontos + equivalente a lista extra pela classificação]** A sua predição final do arquivo `test_X.csv` deve ser enviada para o professor por email. O formato deve ser o mesmo do arquivo `train_y.csv`, assim como exemplificado em `test_example_y.csv` (mas repare que as classes desse último arquivo foram gerados de forma aleatória). Em outras palavras, o arquivo a ser entregue deve ter dois campos. O campo `id` é o identificador do objeto em `test_X.csv` e o campo `label` é a classe que seu modelo encontrou para o objeto em questão. A primeira linha do arquivo deve conter os nomes das colunas.\n",
    "A entrega desse arquivo é obrigatória e vale dois pontos. Além disso, o trabalho com maior _F1 score_ ganhará o equivalente a 100% de uma lista extra. O trabalho com o pior _F1 score_ não ganhará nota extra alguma. Os demais trabalhos terão nota proporcional.\n",
    "O professor se reserva o direito de anular esse quesito (nota extra) se houver indícios de má conduta durante a competição.\n",
    "\n",
    "**Kaggle:** Estou tentando criar uma competição para esse trabalho na plataforma _Kaggle_. Se eu conseguir, compartilho o _link_ com você no _Piazza_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code starts here...\n",
    "# Codigo feito em python 3.6\n",
    "#Lúcio Paulo Reis – 78379\n",
    "#Rafael Victor Costa Braz – 85262\n",
    "#Igor Oliveira – 77431\n",
    "#Tulio Mendonça Cunha dos Santos – 77428\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_validate, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from scipy.stats import randint as sp_randint\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = pd.read_csv('train_X.csv', index_col='id')\n",
    "sr_y = pd.read_csv('train_y.csv', index_col='id', squeeze=True)#Load the values as a Serie\n",
    "df_test_x = pd.read_csv('test_X.csv', index_col='id')\n",
    "categories=['b','d','f','g','h','i','j','n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_scores(model, x, y, cv=5):\n",
    "    scoring = ['f1', 'recall', 'accuracy', 'precision']\n",
    "    scores = cross_validate(model, x, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    print(\"Test Precision: %f\" \n",
    "          % scores['test_precision'].mean())\n",
    "    print(\"Train Precision: %f\" \n",
    "          % scores['train_precision'].mean())\n",
    "    print(\"Test Accuracy: %f\" \n",
    "          % scores['test_accuracy'].mean())\n",
    "    print(\"Train Accuracy: %f\" \n",
    "          % scores['train_accuracy'].mean())\n",
    "    print(\"Test Recall: %f\" \n",
    "          % scores['test_recall'].mean())\n",
    "    print(\"Train Recall: %f\" \n",
    "          % scores['train_recall'].mean())\n",
    "    print(\"Test f1: %f\" \n",
    "          % scores['test_f1'].mean())\n",
    "    print(\"Train f1: %f\" \n",
    "          % scores['train_f1'].mean())\n",
    "    return scores\n",
    "\n",
    "def predict(model, x, y=None, cv=5):\n",
    "    y_pred = cross_val_predict(model,x, y,cv=cv)\n",
    "    conf_mat = pd.DataFrame(confusion_matrix(y,y_pred), \n",
    "                            columns=[\"Predito como 0\", \"Predito como 1\"], \n",
    "                            index=['True 0', 'True 1'])\n",
    "    print(conf_mat)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf = RandomForestClassifier(n_jobs=-1, \n",
    "                                 bootstrap=True,\n",
    "                                 criterion='gini',\n",
    "                                 max_depth=None,\n",
    "                                 max_features=8,\n",
    "                                 min_samples_leaf=1,\n",
    "                                 max_leaf_nodes=23,\n",
    "                                 min_samples_split=9,\n",
    "                                 class_weight=\"balanced\",\n",
    "                                 n_estimators=29)\n",
    "\n",
    "ada_clf = AdaBoostClassifier(rnd_clf,\n",
    "                              algorithm=\"SAMME.R\",\n",
    "                              learning_rate=0.75,\n",
    "                              n_estimators=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision: 0.618913\n",
      "Train Precision: 0.637710\n",
      "Test Accuracy: 0.834021\n",
      "Train Accuracy: 0.847478\n",
      "Test Recall: 0.860823\n",
      "Train Recall: 0.891156\n",
      "Test f1: 0.720053\n",
      "Train f1: 0.743423\n",
      "        Predito como 0  Predito como 1\n",
      "True 0           24940            5309\n",
      "True 1            1385            8588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores(ada_clf, df_x, sr_y);\n",
    "predict(ada_clf, df_x, sr_y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ada_clf.fit(df_x, sr_y)\n",
    "class_pred = ada_clf.predict(df_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([i for i in zip(df_test_x.index, class_pred)], columns=['id','label']).to_csv(\"test_y.csv\", index=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
